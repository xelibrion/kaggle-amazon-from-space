#+BEGIN_SRC ipython :results replace
import numpy as np
import torch
import torch.nn as nn


def logit(p):
    return np.log((p + 1e-8) / (1 - p + 1e-8))
#+END_SRC

Lets say we have 4 different classes.
Distribution of the first 3 are balanced, while the 4th is not.
|   | c1 | c2 | c3 | c4 |
| 0 |    |    |    |    |
| 1 | 10 | 10 | 10 |  5 |

5/35
10/35


#+BEGIN_SRC ipython
y_true = np.array([0, 1, 1, 0], 'float32')
y_pred = np.array([0, 1, 1, 1], 'float32')
#+END_SRC

Then, if we were to specify weights, we should assign a higher weight to the 4th class
#+BEGIN_SRC ipython :results replace
crit = nn.BCEWithLogitsLoss()

in_t = torch.from_numpy(logit(y_pred))
target_t = torch.from_numpy(y_true)
crit(in_t, target_t)

neg_abs = -in_t.abs()
loss = in_t.clamp(min=0) - in_t * target_t + (1 + neg_abs.exp()).log()

loss

loss.mean()

#+END_SRC

#+RESULTS:
: 4.605170249938965
